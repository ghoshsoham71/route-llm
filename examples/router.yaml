# examples/router.yaml
# Example LLM Router configuration.
# Environment variables are interpolated using ${VAR_NAME} syntax.

providers:
  - name: openai
    api_key: "${OPENAI_API_KEY}"
    model: gpt-4o
    rpm_limit: 500
    tpm_limit: 200000
    weight: 0.8

  - name: anthropic
    api_key: "${ANTHROPIC_API_KEY}"
    model: claude-sonnet-4-5
    rpm_limit: 50
    tpm_limit: 200000
    weight: 1.0

  - name: groq
    api_key: "${GROQ_API_KEY}"
    model: llama-3.1-70b-versatile
    rpm_limit: 30
    tpm_limit: 100000
    weight: 0.6

# Scoring weights for the normal priority tier.
# These must sum to <= 1.0.
weights:
  capacity: 0.5
  latency: 0.3
  static: 0.2

# Circuit breaker configuration.
circuit_breaker:
  failure_threshold: 5     # trips after this many consecutive failures
  cooldown_seconds: 30     # provider blocked for this many seconds after trip

# Optional: set to Redis URL to enable multi-instance state sharing.
# redis_url: "redis://localhost:6379"

# Sliding window duration in seconds.
window_seconds: 60

# Fraction of capacity reserved exclusively for high-priority requests.
# Low and normal priority requests cannot use this headroom.
high_priority_reserve_pct: 0.2
